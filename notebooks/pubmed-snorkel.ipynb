{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145dc8bb-1dd2-435d-acf5-f88cda058602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel, MajorityLabelVoter\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a858a24d-7fcf-436b-81ef-b164dea8e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 9\n",
    "output_sfx = '8.26.21-0.9-10.20.21'\n",
    "output_dir = '../input/%dfold/%s' % (n_folds, '%s')\n",
    "train_all_fn = output_dir % ('train-all-%s.pickle' % output_sfx)\n",
    "train_fn = output_dir % ('train-f%s-%s.pickle' % ('%d', output_sfx))\n",
    "valid_fn = output_dir % ('valid-f%s-%s.pickle' % ('%d', output_sfx))\n",
    "test_fn = output_dir % ('test-%s.pickle' % output_sfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298339e1-dc5c-4529-b6f4-dd538d4e8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(prob, true, text='', disp=True):\n",
    "    tmp_zip = zip(true, prob)\n",
    "    recall = [1 if y == 1 and np.argmax(p) == 1\n",
    "              else 0 for y, p in tmp_zip]\n",
    "    tmp_zip = zip(true, prob)\n",
    "    recall_not = [1 if y != 1 and np.argmax(p) != 1\n",
    "                  else 0 for y, p in tmp_zip]\n",
    "    tmp_zip = zip(true, prob)\n",
    "    recall_all = [1 if (y == 1 and np.argmax(p) == 1) \n",
    "                  or (y != 1 and np.argmax(p) != 1) \n",
    "                  else 0 for y, p in tmp_zip]\n",
    "    num_true = np.sum([1 if i == 1 else 0 for i in true])\n",
    "    r_1 = np.sum(recall) / num_true\n",
    "    r0_1 = np.sum(recall_not) / (len(true) - num_true)\n",
    "    rall_1 = np.sum(recall_all) / len(true)\n",
    "    if disp:\n",
    "        print('%s r %.3f r0 %.3f rall %.3f ravg %.3f' % (text, r_1, r0_1, rall_1, (r_1 + r0_1)/2))\n",
    "    return r_1, r0_1, rall_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17a2c7-ca8e-4098-9bfa-2b6c938fedc4",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9328a61c-4d6c-4540-9d08-ae5d09305909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26d135c84b6432184da7976934f1ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trains = []\n",
    "valids = []\n",
    "for n in tqdm(range(n_folds)):\n",
    "    trains.append(pd.read_pickle(train_fn % n))\n",
    "    valids.append(pd.read_pickle(valid_fn % n))\n",
    "\n",
    "train_all = pd.read_pickle(train_all_fn)\n",
    "test = pd.read_pickle(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca896c8-8d8f-4f9d-a6ce-4e3a133a54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_all['Cleaned Abstract']\n",
    "y_train = pd.DataFrame([1 if i == 1 else -1 for i in train_all.Category])\n",
    "\n",
    "X_test = test['Cleaned Abstract']\n",
    "y_test = pd.DataFrame([1 if i == 1 else -1 for i in test.Category])\n",
    "\n",
    "k = 0\n",
    "X_valid = valids[k]['Cleaned Abstract']\n",
    "y_valid = pd.DataFrame([1 if i == 1 else -1 for i in valids[k].Category])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc94ada-6c3c-4c16-9d0d-67737d91b624",
   "metadata": {},
   "source": [
    "## LF labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b541bde4-05fb-4645-93f1-9375252767b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 12326/12326 [00:00<00:00, 12499.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1370/1370 [00:00<00:00, 12104.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12326, 13) (1370, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 12326/12326 [00:01<00:00, 6186.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1370/1370 [00:00<00:00, 6123.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12326, 15) (1370, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos = 1\n",
    "neg = 0\n",
    "abst = -1\n",
    "\n",
    "@labeling_function()\n",
    "def ai(x):\n",
    "    return pos if \"artificial intelligence\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def nn(x):\n",
    "    return pos if \"neural network\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def ml(x):\n",
    "    return pos if \"machine learning\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def dl(x):\n",
    "    return pos if \"deep learning\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def genetic(x):\n",
    "    return pos if \"genetic\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def cnn(x):\n",
    "    return pos if \"convolutional neural network\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def genomic(x):\n",
    "    return pos if \"genomic\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def clingen(x):\n",
    "    return pos if \"clinical genetics\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def medgen(x):\n",
    "    return pos if \"medical genetics\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def medgenom(x):\n",
    "    return pos if \"medical genomics\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def geneticist(x):\n",
    "    return pos if \"geneticist\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def genommed(x):\n",
    "    return pos if \"genomic medicine\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def pm(x):\n",
    "    return pos if \"precision medicine\" in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def gene_noml(x):\n",
    "    return neg if \"gene\" in x['Cleaned Abstract'] and 'machine learning' not in x['Cleaned Abstract'] and 'deep learning' not in x['Cleaned Abstract'] and 'artificial intelligence' not in x['Cleaned Abstract'] else abst\n",
    "\n",
    "@labeling_function()\n",
    "def ml_nogene(x):\n",
    "    return neg if \"gene\" not in x['Cleaned Abstract'] and 'machine learning' in x['Cleaned Abstract'] and 'deep learning' in x['Cleaned Abstract'] and 'artificial intelligence' in x['Cleaned Abstract'] else abst\n",
    "\n",
    "lfs = [ai, nn, ml, dl, genetic, cnn, genomic, clingen, medgen, medgenom, geneticist, genommed, pm]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=train_all)\n",
    "L_test = applier.apply(df=test)\n",
    "print(L_train.shape, L_test.shape)\n",
    "\n",
    "lfs_neg = [ai, nn, ml, dl, genetic, cnn, genomic, clingen, medgen, medgenom, geneticist, genommed, pm, gene_noml, ml_nogene]\n",
    "applier = PandasLFApplier(lfs=lfs_neg)\n",
    "L_train_neg = applier.apply(df=train_all)\n",
    "L_test_neg = applier.apply(df=test)\n",
    "print(L_train_neg.shape, L_test_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d8cb56-ab17-4707-8a7b-ee0b20fdc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_abs = L_train_neg.copy()\n",
    "L_test_abs = L_test_neg.copy()\n",
    "n_lfs = len(lfs_neg)\n",
    "\n",
    "for n in range(L_train_abs.shape[0]):\n",
    "    if L_train_abs[n].sum() == -n_lfs:\n",
    "        L_train_abs[n] = np.zeros(n_lfs)\n",
    "\n",
    "for n in range(L_test_abs.shape[0]):\n",
    "    if L_test_abs[n].sum() == -n_lfs:\n",
    "        L_test_abs[n] = np.zeros(n_lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bb0cec-6f58-4248-8875-2c6aad67b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
      "ai           0      [1]  0.097923  0.072286        0.0        6          0   \n",
      "nn           1      [1]  0.375710  0.330034        0.0       24          0   \n",
      "ml           2      [1]  0.153334  0.129239        0.0       10          0   \n",
      "dl           3      [1]  0.609038  0.323868        0.0       47          0   \n",
      "genetic      4      [1]  0.030261  0.025637        0.0       32          0   \n",
      "cnn          5      [1]  0.226675  0.226675        0.0       13          0   \n",
      "genomic      6      [1]  0.025231  0.022067        0.0        3          0   \n",
      "clingen      7      [1]  0.000325  0.000325        0.0        2          0   \n",
      "medgen       8      [1]  0.000081  0.000081        0.0        0          0   \n",
      "medgenom     9       []  0.000000  0.000000        0.0        0          0   \n",
      "geneticist  10      [1]  0.000568  0.000568        0.0        5          0   \n",
      "genommed    11      [1]  0.000325  0.000325        0.0        0          0   \n",
      "pm          12      [1]  0.009573  0.008762        0.0        2          0   \n",
      "\n",
      "            Emp. Acc.  \n",
      "ai           0.004971  \n",
      "nn           0.005182  \n",
      "ml           0.005291  \n",
      "dl           0.006261  \n",
      "genetic      0.085791  \n",
      "cnn          0.004653  \n",
      "genomic      0.009646  \n",
      "clingen      0.500000  \n",
      "medgen       0.000000  \n",
      "medgenom     0.000000  \n",
      "geneticist   0.714286  \n",
      "genommed     0.000000  \n",
      "pm           0.016949  \n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    print(LFAnalysis(L=L_train, lfs=lfs).lf_summary(y_train.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd33051-9555-4459-bb7b-dcef9f06abea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
      "ai           0      [1]  0.097923  0.072286   0.013062        6       1201   \n",
      "nn           1      [1]  0.375710  0.346503   0.044297       24       4607   \n",
      "ml           2      [1]  0.153334  0.129239   0.013062       10       1880   \n",
      "dl           3      [1]  0.609038  0.323868   0.013062       47       7460   \n",
      "genetic      4      [1]  0.030261  0.030261   0.008356       32        341   \n",
      "cnn          5      [1]  0.226675  0.226675   0.022878       13       2781   \n",
      "genomic      6      [1]  0.025231  0.023528   0.004138        3        308   \n",
      "clingen      7      [1]  0.000325  0.000325   0.000162        2          2   \n",
      "medgen       8      [1]  0.000081  0.000081   0.000081        0          1   \n",
      "medgenom     9       []  0.000000  0.000000   0.000000        0          0   \n",
      "geneticist  10      [1]  0.000568  0.000568   0.000243        5          2   \n",
      "genommed    11      [1]  0.000325  0.000325   0.000000        0          4   \n",
      "pm          12      [1]  0.009573  0.009168   0.001541        2        116   \n",
      "gene_noml   13      [0]  0.088674  0.047623   0.047623     1059         34   \n",
      "ml_nogene   14      [0]  0.013062  0.013062   0.013062      161          0   \n",
      "\n",
      "            Emp. Acc.  \n",
      "ai           0.004971  \n",
      "nn           0.005182  \n",
      "ml           0.005291  \n",
      "dl           0.006261  \n",
      "genetic      0.085791  \n",
      "cnn          0.004653  \n",
      "genomic      0.009646  \n",
      "clingen      0.500000  \n",
      "medgen       0.000000  \n",
      "medgenom     0.000000  \n",
      "geneticist   0.714286  \n",
      "genommed     0.000000  \n",
      "pm           0.016949  \n",
      "gene_noml    0.968893  \n",
      "ml_nogene    1.000000  \n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    print(LFAnalysis(L=L_train_neg, lfs=lfs_neg).lf_summary(np.array([1 if i == 1 else 0 for i in train_all.Category])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff4a758-3122-4edb-9bbf-5dbd82cfe6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
      "ai           0   [0, 1]  0.228379  0.202742   0.013062     1593       1222   \n",
      "nn           1   [0, 1]  0.506166  0.476959   0.044297     1611       4628   \n",
      "ml           2   [0, 1]  0.283790  0.259695   0.013062     1597       1901   \n",
      "dl           3   [0, 1]  0.739494  0.454324   0.013062     1634       7481   \n",
      "genetic      4   [0, 1]  0.160717  0.160717   0.008356     1619        362   \n",
      "cnn          5   [0, 1]  0.357131  0.357131   0.022878     1600       2802   \n",
      "genomic      6   [0, 1]  0.155687  0.153983   0.004138     1590        329   \n",
      "clingen      7   [0, 1]  0.130780  0.130780   0.000162     1589         23   \n",
      "medgen       8   [0, 1]  0.130537  0.130537   0.000081     1587         22   \n",
      "medgenom     9      [0]  0.130456  0.130456   0.000000     1587         21   \n",
      "geneticist  10   [0, 1]  0.131024  0.131024   0.000243     1592         23   \n",
      "genommed    11   [0, 1]  0.130780  0.130780   0.000000     1587         25   \n",
      "pm          12   [0, 1]  0.140029  0.139624   0.001541     1589        137   \n",
      "gene_noml   13      [0]  0.219130  0.178079   0.047623     2646         55   \n",
      "ml_nogene   14      [0]  0.143518  0.143518   0.013062     1748         21   \n",
      "\n",
      "            Emp. Acc.  \n",
      "ai           0.565897  \n",
      "nn           0.258214  \n",
      "ml           0.456547  \n",
      "dl           0.179265  \n",
      "genetic      0.817264  \n",
      "cnn          0.363471  \n",
      "genomic      0.828557  \n",
      "clingen      0.985732  \n",
      "medgen       0.986327  \n",
      "medgenom     0.986940  \n",
      "geneticist   0.985759  \n",
      "genommed     0.984491  \n",
      "pm           0.920626  \n",
      "gene_noml    0.979637  \n",
      "ml_nogene    0.988129  \n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    print(LFAnalysis(L=L_train_abs, lfs=lfs_neg).lf_summary(np.array([1 if i == 1 else 0 for i in train_all.Category])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc12afa-a837-41df-a750-254aadad3831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf 0 category 1: 6 correct out of 115, percent 0.05\n",
      "lf 1 category 1: 24 correct out of 115, percent 0.21\n",
      "lf 2 category 1: 10 correct out of 115, percent 0.09\n",
      "lf 3 category 1: 47 correct out of 115, percent 0.41\n",
      "lf 4 category 1: 32 correct out of 115, percent 0.28\n",
      "lf 5 category 1: 13 correct out of 115, percent 0.11\n",
      "lf 6 category 1: 3 correct out of 115, percent 0.03\n",
      "lf 7 category 1: 2 correct out of 115, percent 0.02\n",
      "lf 8 category 1: 0 correct out of 115, percent 0.00\n",
      "lf 9 category 1: 0 correct out of 115, percent 0.00\n",
      "lf 10 category 1: 5 correct out of 115, percent 0.04\n",
      "lf 11 category 1: 0 correct out of 115, percent 0.00\n",
      "lf 12 category 1: 2 correct out of 115, percent 0.02\n",
      "lf 13 category 1: 0 correct out of 115, percent 0.00\n",
      "lf 14 category 1: 0 correct out of 115, percent 0.00\n"
     ]
    }
   ],
   "source": [
    "for k in range(L_train_neg.shape[1]):\n",
    "    correct = np.sum([1 if L_train_neg[n, k] == 1 and y_train.to_numpy()[n] == 1 else 0 for n in range(L_train_neg.shape[0])])\n",
    "    total = np.sum(train_all.Category == 1)\n",
    "    print('lf %d category 1: %d correct out of %d, percent %.2f' % (k, correct, total, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "011272f8-633e-488c-997c-384e1302e074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf 0 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 1 category 1: 2 correct out of 14, percent 0.14\n",
      "lf 2 category 1: 1 correct out of 14, percent 0.07\n",
      "lf 3 category 1: 3 correct out of 14, percent 0.21\n",
      "lf 4 category 1: 5 correct out of 14, percent 0.36\n",
      "lf 5 category 1: 2 correct out of 14, percent 0.14\n",
      "lf 6 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 7 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 8 category 1: 1 correct out of 14, percent 0.07\n",
      "lf 9 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 10 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 11 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 12 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 13 category 1: 0 correct out of 14, percent 0.00\n",
      "lf 14 category 1: 0 correct out of 14, percent 0.00\n"
     ]
    }
   ],
   "source": [
    "for k in range(L_test_neg.shape[1]):\n",
    "    correct = np.sum([1 if L_test_neg[n, k] == 1 and y_test.to_numpy()[n] == 1 else 0 for n in range(L_test_neg.shape[0])])\n",
    "    total = np.sum(test.Category == 1)\n",
    "    print('lf %d category 1: %d correct out of %d, percent %.2f' % (k, correct, total, correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad6768-f70d-41db-b12a-9f7a839c4128",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BERT labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790bf821-a787-49c8-976e-2796e5eaaa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12326, 9) (1370, 9)\n"
     ]
    }
   ],
   "source": [
    "bert_trains_probs = []\n",
    "bert_tests_probs = []\n",
    "for k in range(n_folds):\n",
    "    with open('../output/bert-9f-multi/train/proba_%d.npy' % k, 'rb') as f:\n",
    "        bert_trains_probs.append(np.load(f))\n",
    "    with open('../output/bert-9f-multi/test/proba_%d.npy' % k, 'rb') as f:\n",
    "        bert_tests_probs.append(np.load(f))\n",
    "bert_trains = np.array([[1 if np.argmax(i) == 0 else 0 for i in fold] for fold in bert_trains_probs]).T\n",
    "bert_tests = np.array([[1 if np.argmax(i) == 0 else 0 for i in fold] for fold in bert_tests_probs]).T\n",
    "print(bert_trains.shape, bert_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa52192b-eb28-4f71-97c7-687d4590c185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
      "0   [0, 1]       1.0       1.0   0.061577    12244         82   0.993347\n",
      "1   [0, 1]       1.0       1.0   0.061577    12091        235   0.980935\n",
      "2   [0, 1]       1.0       1.0   0.061577    12121        205   0.983368\n",
      "3   [0, 1]       1.0       1.0   0.061577    12181        145   0.988236\n",
      "4   [0, 1]       1.0       1.0   0.061577    12215        111   0.990995\n",
      "5   [0, 1]       1.0       1.0   0.061577    12220        106   0.991400\n",
      "6   [0, 1]       1.0       1.0   0.061577    12071        255   0.979312\n",
      "7   [0, 1]       1.0       1.0   0.061577    12211        115   0.990670\n",
      "8   [0, 1]       1.0       1.0   0.061577    12231         95   0.992293\n",
      "  Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
      "0   [0, 1]       1.0       1.0   0.061577       48         67   0.003894\n",
      "1   [0, 1]       1.0       1.0   0.061577       63         52   0.005111\n",
      "2   [0, 1]       1.0       1.0   0.061577       55         60   0.004462\n",
      "3   [0, 1]       1.0       1.0   0.061577       66         49   0.005355\n",
      "4   [0, 1]       1.0       1.0   0.061577       13        102   0.001055\n",
      "5   [0, 1]       1.0       1.0   0.061577       62         53   0.005030\n",
      "6   [0, 1]       1.0       1.0   0.061577       91         24   0.007383\n",
      "7   [0, 1]       1.0       1.0   0.061577       40         75   0.003245\n",
      "8   [0, 1]       1.0       1.0   0.061577       87         28   0.007058\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    tmp_trains = bert_trains.copy()\n",
    "    tmp_trains[tmp_trains == -1] = 0\n",
    "    print(LFAnalysis(L=tmp_trains).lf_summary(np.array([1 if i == 1 else 0 for i in train_all.Category])))\n",
    "    print(LFAnalysis(L=bert_trains).lf_summary(y_train.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c332cabb-0a13-47c1-b07b-b9686d09c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 category 1: 48 correct out of 115, percent 0.42\n",
      "fold 1 category 1: 63 correct out of 115, percent 0.55\n",
      "fold 2 category 1: 55 correct out of 115, percent 0.48\n",
      "fold 3 category 1: 66 correct out of 115, percent 0.57\n",
      "fold 4 category 1: 13 correct out of 115, percent 0.11\n",
      "fold 5 category 1: 62 correct out of 115, percent 0.54\n",
      "fold 6 category 1: 91 correct out of 115, percent 0.79\n",
      "fold 7 category 1: 40 correct out of 115, percent 0.35\n",
      "fold 8 category 1: 87 correct out of 115, percent 0.76\n"
     ]
    }
   ],
   "source": [
    "for k in range(bert_trains.shape[1]):\n",
    "    correct = np.sum([1 if bert_trains[n, k] == 1 and y_train.to_numpy()[n] == 1 else 0 for n in range(bert_trains.shape[0])])\n",
    "    total = np.sum(train_all.Category == 1)\n",
    "    print('fold %d category 1: %d correct out of %d, percent %.2f' % (k, correct, total, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04bcda90-ac2e-4e50-ba98-fd1d2b5157e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 category 1: 2 correct out of 14, percent 0.14\n",
      "fold 1 category 1: 8 correct out of 14, percent 0.57\n",
      "fold 2 category 1: 7 correct out of 14, percent 0.50\n",
      "fold 3 category 1: 3 correct out of 14, percent 0.21\n",
      "fold 4 category 1: 0 correct out of 14, percent 0.00\n",
      "fold 5 category 1: 4 correct out of 14, percent 0.29\n",
      "fold 6 category 1: 9 correct out of 14, percent 0.64\n",
      "fold 7 category 1: 3 correct out of 14, percent 0.21\n",
      "fold 8 category 1: 9 correct out of 14, percent 0.64\n"
     ]
    }
   ],
   "source": [
    "for k in range(bert_tests.shape[1]):\n",
    "    correct = np.sum([1 if bert_tests[n, k] == 1 and y_train.to_numpy()[n] == 1 else 0 for n in range(bert_tests.shape[0])])\n",
    "    total = np.sum(test.Category == 1)\n",
    "    print('fold %d category 1: %d correct out of %d, percent %.2f' % (k, correct, total, correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56011812-03d0-4e33-8478-3d33a245d1e7",
   "metadata": {},
   "source": [
    "## RF labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07292f77-ca58-4917-8925-783497ff71ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12326, 9) (1370, 9)\n"
     ]
    }
   ],
   "source": [
    "rf_trains_probs = []\n",
    "rf_tests_probs = []\n",
    "for k in range(n_folds):\n",
    "    with open('../output/rf-%df-multi/train/k%d.npy' % (n_folds, k), 'rb') as f:\n",
    "        rf_trains_probs.append(np.load(f))\n",
    "    with open('../output/rf-%df-multi/test/k%d.npy' % (n_folds, k), 'rb') as f:\n",
    "        rf_tests_probs.append(np.load(f))\n",
    "rf_trains = np.array([[1 if np.argmax(i) == 0 else -1 for i in fold] for fold in rf_trains_probs]).T\n",
    "rf_tests = np.array([[1 if np.argmax(i) == 0 else -1 for i in fold] for fold in rf_tests_probs]).T\n",
    "print(rf_trains.shape, rf_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61518942-1a4f-4e0d-8b67-89e7b73d09f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
      "0   [0, 1]       1.0       1.0   0.009086    12314         12   0.999026\n",
      "1   [0, 1]       1.0       1.0   0.009086    12313         13   0.998945\n",
      "2   [0, 1]       1.0       1.0   0.009086    12313         13   0.998945\n",
      "3   [0, 1]       1.0       1.0   0.009086    12313         13   0.998945\n",
      "4   [0, 1]       1.0       1.0   0.009086    12314         12   0.999026\n",
      "5   [0, 1]       1.0       1.0   0.009086    12313         13   0.998945\n",
      "6   [0, 1]       1.0       1.0   0.009086    12313         13   0.998945\n",
      "7   [0, 1]       1.0       1.0   0.009086    12314         12   0.999026\n",
      "8   [0, 1]       1.0       1.0   0.009086    12315         11   0.999108\n",
      "  Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
      "0      [1]  0.008356  0.008356        0.0      103          0        1.0\n",
      "1      [1]  0.008275  0.008275        0.0      102          0        1.0\n",
      "2      [1]  0.008275  0.008275        0.0      102          0        1.0\n",
      "3      [1]  0.008275  0.008275        0.0      102          0        1.0\n",
      "4      [1]  0.008356  0.008356        0.0      103          0        1.0\n",
      "5      [1]  0.008275  0.008275        0.0      102          0        1.0\n",
      "6      [1]  0.008275  0.008275        0.0      102          0        1.0\n",
      "7      [1]  0.008356  0.008356        0.0      103          0        1.0\n",
      "8      [1]  0.008437  0.008437        0.0      104          0        1.0\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    tmp_trains = rf_trains.copy()\n",
    "    tmp_trains[tmp_trains == -1] = 0\n",
    "    print(LFAnalysis(L=tmp_trains).lf_summary(np.array([1 if i == 1 else 0 for i in train_all.Category])))\n",
    "    print(LFAnalysis(L=rf_trains).lf_summary(y_train.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba47138f-3dc9-4947-8bb1-e8e48dce239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 category 1: 103 correct out of 115, percent 0.90\n",
      "fold 1 category 1: 102 correct out of 115, percent 0.89\n",
      "fold 2 category 1: 102 correct out of 115, percent 0.89\n",
      "fold 3 category 1: 102 correct out of 115, percent 0.89\n",
      "fold 4 category 1: 103 correct out of 115, percent 0.90\n",
      "fold 5 category 1: 102 correct out of 115, percent 0.89\n",
      "fold 6 category 1: 102 correct out of 115, percent 0.89\n",
      "fold 7 category 1: 103 correct out of 115, percent 0.90\n",
      "fold 8 category 1: 104 correct out of 115, percent 0.90\n"
     ]
    }
   ],
   "source": [
    "for k in range(rf_trains.shape[1]):\n",
    "    correct = np.sum([1 if rf_trains[n, k] == 1 and y_train.to_numpy()[n] == 1 else 0 for n in range(rf_trains.shape[0])])\n",
    "    total = np.sum(train_all.Category == 1)\n",
    "    print('fold %d category 1: %d correct out of %d, percent %.2f' % (k, correct, total, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edc26465-f58e-42ee-9558-bbeb10d4b021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 category 1: 0 correct out of 14, percent 0.00\n",
      "fold 1 category 1: 0 correct out of 14, percent 0.00\n",
      "fold 2 category 1: 0 correct out of 14, percent 0.00\n",
      "fold 3 category 1: 0 correct out of 14, percent 0.00\n",
      "fold 4 category 1: 3 correct out of 14, percent 0.21\n",
      "fold 5 category 1: 0 correct out of 14, percent 0.00\n",
      "fold 6 category 1: 1 correct out of 14, percent 0.07\n",
      "fold 7 category 1: 1 correct out of 14, percent 0.07\n",
      "fold 8 category 1: 0 correct out of 14, percent 0.00\n"
     ]
    }
   ],
   "source": [
    "for k in range(rf_tests.shape[1]):\n",
    "    correct = np.sum([1 if rf_tests[n, k] == 1 and y_test.to_numpy()[n] == 1 else 0 for n in range(rf_tests.shape[0])])\n",
    "    total = np.sum(test.Category == 1)\n",
    "    print('fold %d category 1: %d correct out of %d, percent %.2f' % (k, correct, total, correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868448c-4f49-4b51-bc6f-62cd2e265961",
   "metadata": {},
   "source": [
    "## Simple Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2767a9-a19d-4580-88d3-ba9874c8a4f4",
   "metadata": {},
   "source": [
    "### RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59d9c4a2-8ec9-4bfa-aa87-64839220f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Average RFs r 0.000 r0 1.000 rall 0.990 ravg 0.500\n"
     ]
    }
   ],
   "source": [
    "recall(np.mean(rf_tests_probs, axis=0), test.Category, text='Simple Average RFs');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b113bb-a090-4723-9bdf-936b06fa0e23",
   "metadata": {},
   "source": [
    "### BERTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ad99b4e-beb6-4392-b10f-829c42a89869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Average BERTs r 0.000 r0 0.996 rall 0.986 ravg 0.498\n"
     ]
    }
   ],
   "source": [
    "recall(np.mean(bert_tests_probs, axis=0), test.Category, text='Simple Average BERTs');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc66991-0bff-4d7a-9e9b-1de12bb582e9",
   "metadata": {},
   "source": [
    "## Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d5af79a-78e0-4ca6-b3eb-d53b33b13922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snork(L_train, L_test, y_true):\n",
    "    logger.setLevel(logging.CRITICAL)\n",
    "    label_model = LabelModel(cardinality=2, verbose=True)\n",
    "    label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "    label_model_acc = label_model.score(L=L_test, Y=y_true, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "    print(f\"{'Label Accuracy:':<25} {label_model_acc * 100:.1f}%\")\n",
    "    label_prob = label_model.predict_proba(L=L_test)\n",
    "    \n",
    "    y = y_true[0].tolist()\n",
    "    p = np.sum([1 for i in y if i == 1])\n",
    "    n = len(y) - p\n",
    "    \n",
    "    tp = np.sum([1 for i in range(y_true.shape[0]) if label_prob[i][1] > 0.5 and y[i] == 1])\n",
    "    fp = np.sum([1 for i in range(y_true.shape[0]) if label_prob[i][1] > 0.5 and y[i] != 1])\n",
    "    tn = np.sum([1 for i in range(y_true.shape[0]) if label_prob[i][1] <= 0.5 and y[i] != 1])\n",
    "    fn = np.sum([1 for i in range(y_true.shape[0]) if label_prob[i][1] <= 0.5 and y[i] == 1])\n",
    "    \n",
    "    print('tp %d fp %d tn %d fn %d' % (tp, fp, tn, fn))\n",
    "    print('tpr %.3f fnr %.3f' % (tp / p, fn / p))\n",
    "    print('fpr %.3f tnr %.3f' % (fp / n, tn / n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308ee1e-4177-4493-ae22-98158f05bfcf",
   "metadata": {},
   "source": [
    "### LFs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b784907c-7783-4046-a781-2138deec3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|                                                                             | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.277]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.002]\n",
      " 32%|████████████████████▋                                            | 159/500 [00:00<00:00, 1581.42epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 67%|███████████████████████████████████████████▍                     | 334/500 [00:00<00:00, 1675.67epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1698.09epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           21.4%\n",
      "tp 2 fp 513 tn 843 fn 12\n",
      "tpr 0.143 fnr 0.857\n",
      "fpr 0.378 tnr 0.622\n"
     ]
    }
   ],
   "source": [
    "snork(L_train, L_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "602e4320-8ed3-40a4-bc04-2e9cb651330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1740.65epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           64.3%\n",
      "tp 8 fp 575 tn 781 fn 6\n",
      "tpr 0.571 fnr 0.429\n",
      "fpr 0.424 tnr 0.576\n"
     ]
    }
   ],
   "source": [
    "snork(L_train_neg, L_test_neg, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd7e339d-e83e-444e-8391-e26ddaaf9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1739.18epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           35.7%\n",
      "tp 5 fp 1074 tn 282 fn 9\n",
      "tpr 0.357 fnr 0.643\n",
      "fpr 0.792 tnr 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snork(L_train_abs, L_test_abs, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385bdbcb-50a1-4123-95b4-16131b195106",
   "metadata": {},
   "source": [
    "### RFs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68349b1a-f3cf-473e-9c2c-bf140883e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1835.28epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           50.0%\n",
      "tp 3 fp 0 tn 1356 fn 11\n",
      "tpr 0.214 fnr 0.786\n",
      "fpr 0.000 tnr 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snork(rf_trains, rf_tests, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1920f0-77a6-4c8b-acac-867f0602ab09",
   "metadata": {},
   "source": [
    "### BERT only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5397ac15-c95d-4970-adcd-a13daddb5e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1838.95epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           100.0%\n",
      "tp 14 fp 75 tn 1281 fn 0\n",
      "tpr 1.000 fnr 0.000\n",
      "fpr 0.055 tnr 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snork(bert_trains, bert_tests, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27983097-9162-4002-ad5b-4c8076715172",
   "metadata": {},
   "source": [
    "### LFs + RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57dd63a5-3a95-41f8-b497-3be412612e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1695.31epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           21.4%\n",
      "tp 2 fp 513 tn 843 fn 12\n",
      "tpr 0.143 fnr 0.857\n",
      "fpr 0.378 tnr 0.622\n"
     ]
    }
   ],
   "source": [
    "train_stack = np.hstack((L_train, rf_trains))\n",
    "test_stack = np.hstack((L_test, rf_tests))\n",
    "snork(train_stack, test_stack, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2058550-60b5-43ce-ae00-6d47f063df14",
   "metadata": {},
   "source": [
    "### LFs + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e9934de-ff63-4b1d-aa57-2f458dee408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1630.81epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           14.3%\n",
      "tp 2 fp 512 tn 844 fn 12\n",
      "tpr 0.143 fnr 0.857\n",
      "fpr 0.378 tnr 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_stack = np.hstack((L_train, bert_trains))\n",
    "test_stack = np.hstack((L_test, bert_tests))\n",
    "snork(train_stack, test_stack, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de951bb-1dfa-42fc-81af-1210bc6f4f66",
   "metadata": {},
   "source": [
    "### RFs + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "958c40cf-e6e1-4333-a37a-e925739bf130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1693.86epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           100.0%\n",
      "tp 14 fp 75 tn 1281 fn 0\n",
      "tpr 1.000 fnr 0.000\n",
      "fpr 0.055 tnr 0.945\n"
     ]
    }
   ],
   "source": [
    "train_stack = np.hstack((rf_trains, bert_trains))\n",
    "test_stack = np.hstack((rf_tests, bert_tests))\n",
    "snork(train_stack, test_stack, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ebf1f-bf92-46d9-aebc-d62e28dfa204",
   "metadata": {},
   "source": [
    "### LFs + RFs + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbe29153-ea04-4aa8-bb0b-a9a9ba3911d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 849.01epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Accuracy:           14.3%\n",
      "tp 2 fp 512 tn 844 fn 12\n",
      "tpr 0.143 fnr 0.857\n",
      "fpr 0.378 tnr 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_stack = np.hstack((L_train, rf_trains, bert_trains))\n",
    "test_stack = np.hstack((L_test, rf_tests, bert_tests))\n",
    "snork(train_stack, test_stack, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49297a-ed65-4d0e-b73f-8331c99b5627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
