{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b2e206-1c1c-4861-9a08-0148e842cf90",
   "metadata": {},
   "source": [
    "# Pubmed Paper Clasification - Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db4974-3987-4974-820f-c49fcfb80b2e",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734526eb-9479-4736-bcc8-5bd0a9f6ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as _tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "no_punc = str.maketrans('', '', string.punctuation)\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "porter = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4673f640-250c-499c-8de0-a29d7046e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.26.21-0.9-10.20.21\n"
     ]
    }
   ],
   "source": [
    "input_dt = '8.26.21'\n",
    "train_frac = 0.9\n",
    "output_dt = '10.20.21'\n",
    "output_sfx = '%s-%.1f-%s' % (input_dt, train_frac, output_dt)\n",
    "print(output_sfx)\n",
    "\n",
    "input_fn = '../input/abstracts-%s.pickle' % input_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0a56d-c0f2-4b07-a8c0-ffef79050c35",
   "metadata": {},
   "source": [
    "## Read in abstract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1cadd1-18eb-41f5-808d-60002f5a2c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9713</td>\n",
       "      <td>9713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1459</td>\n",
       "      <td>1459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PMID  Abstract\n",
       "Category                \n",
       "1          128       128\n",
       "3          114       114\n",
       "4         9713      9713\n",
       "5           17        17\n",
       "6            8         8\n",
       "7         2019      2019\n",
       "8          116       116\n",
       "9          122       122\n",
       "10        1459      1459"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm = pd.read_pickle(input_fn)\n",
    "pm.groupby('Category').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e8ff7-a413-4ece-94a3-a2b726d0f619",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Derive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c88eff-61f5-43c4-bd0b-95bb62e1070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isletters(word):\n",
    "    for c in word:\n",
    "        if c < 'a' or c > 'z':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def isletterornum(word):\n",
    "    for c in word:\n",
    "        if (c < 'a' or c > 'z') and (c < '0' or c > '9'):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e670ac5c-773a-4f86-b6e2-818b0da8abb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isletters('ψ secondari structur sequenc'), isletters('yeet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af0d27-2281-4890-87a8-a4cbf33f5b1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fd5fa0-8879-44c7-a58b-0cda093946db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_abstract(abstract):\n",
    "    custom_drop = []\n",
    "    cleaned = [w.lower().translate(no_punc) for w in abstract.split(' ')]\n",
    "    dropped = [w for w in cleaned if w not in stop_words and w not in custom_drop]\n",
    "    return ' '.join(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177ab586-f65c-46b2-83d2-333f18b73623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Cleaned Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25553339</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebellar ataxia is a progressive neuro-degen...</td>\n",
       "      <td>cerebellar ataxia progressive neurodegenerativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26663098</td>\n",
       "      <td>1</td>\n",
       "      <td>Facial analysis systems are becoming available...</td>\n",
       "      <td>facial analysis systems becoming available hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27014455</td>\n",
       "      <td>1</td>\n",
       "      <td>Patients with Williams-Beuren Syndrome can be ...</td>\n",
       "      <td>patients williamsbeuren syndrome recognized cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27112773</td>\n",
       "      <td>1</td>\n",
       "      <td>The genetic basis of numerous intellectual dis...</td>\n",
       "      <td>genetic basis numerous intellectual disability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27356087</td>\n",
       "      <td>1</td>\n",
       "      <td>We report four individuals from two unrelated ...</td>\n",
       "      <td>report four individuals two unrelated consangu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>34231311</td>\n",
       "      <td>10</td>\n",
       "      <td>Deep learning (DL) has shown rapid advancement...</td>\n",
       "      <td>deep learning dl shown rapid advancement consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>34231533</td>\n",
       "      <td>10</td>\n",
       "      <td>Systemic retinal biomarkers are biomarkers ide...</td>\n",
       "      <td>systemic retinal biomarkers biomarkers identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13693</th>\n",
       "      <td>34233515</td>\n",
       "      <td>10</td>\n",
       "      <td>In the last few years, artificial intelligence...</td>\n",
       "      <td>last years artificial intelligence ai research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13694</th>\n",
       "      <td>34234854</td>\n",
       "      <td>10</td>\n",
       "      <td>Despite the significant progress in diagnosis ...</td>\n",
       "      <td>despite significant progress diagnosis treatme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13695</th>\n",
       "      <td>34235035</td>\n",
       "      <td>10</td>\n",
       "      <td>Machine learning (ML) is a set of models and m...</td>\n",
       "      <td>machine learning ml set models methods detect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13696 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PMID  Category                                           Abstract  \\\n",
       "0      25553339         1  Cerebellar ataxia is a progressive neuro-degen...   \n",
       "1      26663098         1  Facial analysis systems are becoming available...   \n",
       "2      27014455         1  Patients with Williams-Beuren Syndrome can be ...   \n",
       "3      27112773         1  The genetic basis of numerous intellectual dis...   \n",
       "4      27356087         1  We report four individuals from two unrelated ...   \n",
       "...         ...       ...                                                ...   \n",
       "13691  34231311        10  Deep learning (DL) has shown rapid advancement...   \n",
       "13692  34231533        10  Systemic retinal biomarkers are biomarkers ide...   \n",
       "13693  34233515        10  In the last few years, artificial intelligence...   \n",
       "13694  34234854        10  Despite the significant progress in diagnosis ...   \n",
       "13695  34235035        10  Machine learning (ML) is a set of models and m...   \n",
       "\n",
       "                                        Cleaned Abstract  \n",
       "0      cerebellar ataxia progressive neurodegenerativ...  \n",
       "1      facial analysis systems becoming available hea...  \n",
       "2      patients williamsbeuren syndrome recognized cl...  \n",
       "3      genetic basis numerous intellectual disability...  \n",
       "4      report four individuals two unrelated consangu...  \n",
       "...                                                  ...  \n",
       "13691  deep learning dl shown rapid advancement consi...  \n",
       "13692  systemic retinal biomarkers biomarkers identif...  \n",
       "13693  last years artificial intelligence ai research...  \n",
       "13694  despite significant progress diagnosis treatme...  \n",
       "13695  machine learning ml set models methods detect ...  \n",
       "\n",
       "[13696 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm['Cleaned Abstract'] = pm.apply(lambda x: clean_abstract(x.Abstract), axis=1)\n",
    "pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895fc0ea-f456-4f31-8d0a-045c2ea5c8fc",
   "metadata": {},
   "source": [
    "### Stem abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a9275c-7209-4121-9ce3-2dfb6ef76e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 13696/13696 [00:59<00:00, 231.51it/s]\n"
     ]
    }
   ],
   "source": [
    "def stem_abstract(abstract):\n",
    "    # sentence tokenize and remove punctuation, non-alpha, stop-words\n",
    "    tmp_sent = nltk.sent_tokenize(abstract)\n",
    "    tmp_sent = [nltk.word_tokenize(s.translate(no_punc).lower()) for s in tmp_sent]\n",
    "#     tmp_sent = [[w for w in s if not w in stop_words and w.isalpha()] for s in tmp_sent]\n",
    "#     tmp_sent = [[w for w in s if not w in stop_words and isletters(w)] for s in tmp_sent]\n",
    "#     tmp_sent = [[w for w in s if not w in stop_words and isletterornum(w)] for s in tmp_sent]\n",
    "#     tmp_sent = [[w for w in s if not w in stop_words and not w.isdigit()] for s in tmp_sent]\n",
    "    tmp_sent = [[w for w in s if not w in stop_words and not w.isdigit() and isletterornum(w)] for s in tmp_sent]\n",
    "    tmp_stem = [[porter.stem(w) for w in s] for s in tmp_sent]\n",
    "#     tmp_gram = [' '.join(g) for s in tmp_stem for g in nltk.ngrams(s, n)]\n",
    "#     return ' '.join([' '.join(s) for s in tmp_stem]), tmp_gram\n",
    "    return tmp_stem\n",
    "\n",
    "stemmed = [stem_abstract(a) for a in _tqdm(pm.Abstract.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df64083-0817-4178-963b-657be11db7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Cleaned Abstract</th>\n",
       "      <th>Stemmed Abstract</th>\n",
       "      <th>Stemmed 2ngram</th>\n",
       "      <th>Stemmed 3ngram</th>\n",
       "      <th>Stemmed 4ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25553339</td>\n",
       "      <td>1</td>\n",
       "      <td>Cerebellar ataxia is a progressive neuro-degen...</td>\n",
       "      <td>cerebellar ataxia progressive neurodegenerativ...</td>\n",
       "      <td>cerebellar ataxia progress neurodegen diseas m...</td>\n",
       "      <td>[cerebellar ataxia, ataxia progress, progress ...</td>\n",
       "      <td>[cerebellar ataxia progress, ataxia progress n...</td>\n",
       "      <td>[cerebellar ataxia progress neurodegen, ataxia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26663098</td>\n",
       "      <td>1</td>\n",
       "      <td>Facial analysis systems are becoming available...</td>\n",
       "      <td>facial analysis systems becoming available hea...</td>\n",
       "      <td>facial analysi system becom avail healthcar pr...</td>\n",
       "      <td>[facial analysi, analysi system, system becom,...</td>\n",
       "      <td>[facial analysi system, analysi system becom, ...</td>\n",
       "      <td>[facial analysi system becom, analysi system b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27014455</td>\n",
       "      <td>1</td>\n",
       "      <td>Patients with Williams-Beuren Syndrome can be ...</td>\n",
       "      <td>patients williamsbeuren syndrome recognized cl...</td>\n",
       "      <td>patient williamsbeuren syndrom recogn clinic g...</td>\n",
       "      <td>[patient williamsbeuren, williamsbeuren syndro...</td>\n",
       "      <td>[patient williamsbeuren syndrom, williamsbeure...</td>\n",
       "      <td>[patient williamsbeuren syndrom recogn, willia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27112773</td>\n",
       "      <td>1</td>\n",
       "      <td>The genetic basis of numerous intellectual dis...</td>\n",
       "      <td>genetic basis numerous intellectual disability...</td>\n",
       "      <td>genet basi numer intellectu disabl id syndrom ...</td>\n",
       "      <td>[genet basi, basi numer, numer intellectu, int...</td>\n",
       "      <td>[genet basi numer, basi numer intellectu, nume...</td>\n",
       "      <td>[genet basi numer intellectu, basi numer intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27356087</td>\n",
       "      <td>1</td>\n",
       "      <td>We report four individuals from two unrelated ...</td>\n",
       "      <td>report four individuals two unrelated consangu...</td>\n",
       "      <td>report four individu two unrel consanguin fami...</td>\n",
       "      <td>[report four, four individu, individu two, two...</td>\n",
       "      <td>[report four individu, four individu two, indi...</td>\n",
       "      <td>[report four individu two, four individu two u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>34231311</td>\n",
       "      <td>10</td>\n",
       "      <td>Deep learning (DL) has shown rapid advancement...</td>\n",
       "      <td>deep learning dl shown rapid advancement consi...</td>\n",
       "      <td>deep learn dl shown rapid advanc consider prom...</td>\n",
       "      <td>[deep learn, learn dl, dl shown, shown rapid, ...</td>\n",
       "      <td>[deep learn dl, learn dl shown, dl shown rapid...</td>\n",
       "      <td>[deep learn dl shown, learn dl shown rapid, dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>34231533</td>\n",
       "      <td>10</td>\n",
       "      <td>Systemic retinal biomarkers are biomarkers ide...</td>\n",
       "      <td>systemic retinal biomarkers biomarkers identif...</td>\n",
       "      <td>system retin biomark biomark identifi retina r...</td>\n",
       "      <td>[system retin, retin biomark, biomark biomark,...</td>\n",
       "      <td>[system retin biomark, retin biomark biomark, ...</td>\n",
       "      <td>[system retin biomark biomark, retin biomark b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13693</th>\n",
       "      <td>34233515</td>\n",
       "      <td>10</td>\n",
       "      <td>In the last few years, artificial intelligence...</td>\n",
       "      <td>last years artificial intelligence ai research...</td>\n",
       "      <td>last year artifici intellig ai research rapidl...</td>\n",
       "      <td>[last year, year artifici, artifici intellig, ...</td>\n",
       "      <td>[last year artifici, year artifici intellig, a...</td>\n",
       "      <td>[last year artifici intellig, year artifici in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13694</th>\n",
       "      <td>34234854</td>\n",
       "      <td>10</td>\n",
       "      <td>Despite the significant progress in diagnosis ...</td>\n",
       "      <td>despite significant progress diagnosis treatme...</td>\n",
       "      <td>despit signific progress diagnosi treatment pa...</td>\n",
       "      <td>[despit signific, signific progress, progress ...</td>\n",
       "      <td>[despit signific progress, signific progress d...</td>\n",
       "      <td>[despit signific progress diagnosi, signific p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13695</th>\n",
       "      <td>34235035</td>\n",
       "      <td>10</td>\n",
       "      <td>Machine learning (ML) is a set of models and m...</td>\n",
       "      <td>machine learning ml set models methods detect ...</td>\n",
       "      <td>machin learn ml set model method detect patter...</td>\n",
       "      <td>[machin learn, learn ml, ml set, set model, mo...</td>\n",
       "      <td>[machin learn ml, learn ml set, ml set model, ...</td>\n",
       "      <td>[machin learn ml set, learn ml set model, ml s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13696 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PMID  Category                                           Abstract  \\\n",
       "0      25553339         1  Cerebellar ataxia is a progressive neuro-degen...   \n",
       "1      26663098         1  Facial analysis systems are becoming available...   \n",
       "2      27014455         1  Patients with Williams-Beuren Syndrome can be ...   \n",
       "3      27112773         1  The genetic basis of numerous intellectual dis...   \n",
       "4      27356087         1  We report four individuals from two unrelated ...   \n",
       "...         ...       ...                                                ...   \n",
       "13691  34231311        10  Deep learning (DL) has shown rapid advancement...   \n",
       "13692  34231533        10  Systemic retinal biomarkers are biomarkers ide...   \n",
       "13693  34233515        10  In the last few years, artificial intelligence...   \n",
       "13694  34234854        10  Despite the significant progress in diagnosis ...   \n",
       "13695  34235035        10  Machine learning (ML) is a set of models and m...   \n",
       "\n",
       "                                        Cleaned Abstract  \\\n",
       "0      cerebellar ataxia progressive neurodegenerativ...   \n",
       "1      facial analysis systems becoming available hea...   \n",
       "2      patients williamsbeuren syndrome recognized cl...   \n",
       "3      genetic basis numerous intellectual disability...   \n",
       "4      report four individuals two unrelated consangu...   \n",
       "...                                                  ...   \n",
       "13691  deep learning dl shown rapid advancement consi...   \n",
       "13692  systemic retinal biomarkers biomarkers identif...   \n",
       "13693  last years artificial intelligence ai research...   \n",
       "13694  despite significant progress diagnosis treatme...   \n",
       "13695  machine learning ml set models methods detect ...   \n",
       "\n",
       "                                        Stemmed Abstract  \\\n",
       "0      cerebellar ataxia progress neurodegen diseas m...   \n",
       "1      facial analysi system becom avail healthcar pr...   \n",
       "2      patient williamsbeuren syndrom recogn clinic g...   \n",
       "3      genet basi numer intellectu disabl id syndrom ...   \n",
       "4      report four individu two unrel consanguin fami...   \n",
       "...                                                  ...   \n",
       "13691  deep learn dl shown rapid advanc consider prom...   \n",
       "13692  system retin biomark biomark identifi retina r...   \n",
       "13693  last year artifici intellig ai research rapidl...   \n",
       "13694  despit signific progress diagnosi treatment pa...   \n",
       "13695  machin learn ml set model method detect patter...   \n",
       "\n",
       "                                          Stemmed 2ngram  \\\n",
       "0      [cerebellar ataxia, ataxia progress, progress ...   \n",
       "1      [facial analysi, analysi system, system becom,...   \n",
       "2      [patient williamsbeuren, williamsbeuren syndro...   \n",
       "3      [genet basi, basi numer, numer intellectu, int...   \n",
       "4      [report four, four individu, individu two, two...   \n",
       "...                                                  ...   \n",
       "13691  [deep learn, learn dl, dl shown, shown rapid, ...   \n",
       "13692  [system retin, retin biomark, biomark biomark,...   \n",
       "13693  [last year, year artifici, artifici intellig, ...   \n",
       "13694  [despit signific, signific progress, progress ...   \n",
       "13695  [machin learn, learn ml, ml set, set model, mo...   \n",
       "\n",
       "                                          Stemmed 3ngram  \\\n",
       "0      [cerebellar ataxia progress, ataxia progress n...   \n",
       "1      [facial analysi system, analysi system becom, ...   \n",
       "2      [patient williamsbeuren syndrom, williamsbeure...   \n",
       "3      [genet basi numer, basi numer intellectu, nume...   \n",
       "4      [report four individu, four individu two, indi...   \n",
       "...                                                  ...   \n",
       "13691  [deep learn dl, learn dl shown, dl shown rapid...   \n",
       "13692  [system retin biomark, retin biomark biomark, ...   \n",
       "13693  [last year artifici, year artifici intellig, a...   \n",
       "13694  [despit signific progress, signific progress d...   \n",
       "13695  [machin learn ml, learn ml set, ml set model, ...   \n",
       "\n",
       "                                          Stemmed 4ngram  \n",
       "0      [cerebellar ataxia progress neurodegen, ataxia...  \n",
       "1      [facial analysi system becom, analysi system b...  \n",
       "2      [patient williamsbeuren syndrom recogn, willia...  \n",
       "3      [genet basi numer intellectu, basi numer intel...  \n",
       "4      [report four individu two, four individu two u...  \n",
       "...                                                  ...  \n",
       "13691  [deep learn dl shown, learn dl shown rapid, dl...  \n",
       "13692  [system retin biomark biomark, retin biomark b...  \n",
       "13693  [last year artifici intellig, year artifici in...  \n",
       "13694  [despit signific progress diagnosi, signific p...  \n",
       "13695  [machin learn ml set, learn ml set model, ml s...  \n",
       "\n",
       "[13696 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pm['Stemmed Abstract'] = pm.apply(lambda x: stem_abstract(x.Abstract, n=n_grams), axis=1)\n",
    "# pm['Stemmed ngram'] = pm.apply(lambda x: stem_abstract(x.Abstract, n=n_grams), axis=1)\n",
    "\n",
    "\n",
    "pm['Stemmed Abstract'] = [' '.join([' '.join(s) for s in ab]) for ab in stemmed]\n",
    "pm['Stemmed 2ngram'] = [[' '.join(g) for s in ab for g in nltk.ngrams(s, 2)] for ab in stemmed]\n",
    "pm['Stemmed 3ngram'] = [[' '.join(g) for s in ab for g in nltk.ngrams(s, 3)] for ab in stemmed]\n",
    "pm['Stemmed 4ngram'] = [[' '.join(g) for s in ab for g in nltk.ngrams(s, 4)] for ab in stemmed]\n",
    "pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f8bf28-4bad-4e4b-9282-e7f0f67ad021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ngram | pre-dedupe 1318972 | post-dedupe 566633\n",
      "3ngram | pre-dedupe 1223441 | post-dedupe 1013520\n",
      "4ngram | pre-dedupe 1128023 | post-dedupe 1061826\n"
     ]
    }
   ],
   "source": [
    "unique = [g for ab in pm['Stemmed 2ngram'].tolist() for g in ab]\n",
    "print('2ngram | pre-dedupe', len(unique), '| post-dedupe', len(list(set(unique))))\n",
    "\n",
    "unique = [g for ab in pm['Stemmed 3ngram'].tolist() for g in ab]\n",
    "print('3ngram | pre-dedupe', len(unique), '| post-dedupe', len(list(set(unique))))\n",
    "\n",
    "unique = [g for ab in pm['Stemmed 4ngram'].tolist() for g in ab]\n",
    "print('4ngram | pre-dedupe', len(unique), '| post-dedupe', len(list(set(unique))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063acce0-182d-4864-af8c-7f8072f44353",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42b6024-729e-4759-8927-b21e90a33373",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 9\n",
    "\n",
    "output_dir = '../input/%dfold/%s' % (n_folds, '%s')\n",
    "Path(output_dir % '').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_all_fn = output_dir % ('train-all-%s.pickle' % output_sfx)\n",
    "train_fn = output_dir % ('train-f%s-%s.pickle' % ('%d', output_sfx))\n",
    "valid_fn = output_dir % ('valid-f%s-%s.pickle' % ('%d', output_sfx))\n",
    "test_fn = output_dir % ('test-%s.pickle' % output_sfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ff116c-3544-4ef9-8cb7-a31322cd8e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12326, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "for i in pm.Category.unique():\n",
    "    train.append(pm[pm.Category == i].sample(frac=train_frac, random_state=420))\n",
    "\n",
    "train = pd.concat(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0636da-2891-467e-be9c-3e89b72b2b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train 10953 valid 1373 total 12326 match True',\n",
       " 'train 10953 valid 1373 total 12326 match True',\n",
       " 'train 10954 valid 1372 total 12326 match True',\n",
       " 'train 10955 valid 1371 total 12326 match True',\n",
       " 'train 10956 valid 1370 total 12326 match True',\n",
       " 'train 10957 valid 1369 total 12326 match True',\n",
       " 'train 10958 valid 1368 total 12326 match True',\n",
       " 'train 10960 valid 1366 total 12326 match True',\n",
       " 'train 10962 valid 1364 total 12326 match True']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = [[] for _ in range(n_folds)]\n",
    "\n",
    "for i in pm.Category.unique():\n",
    "    split_tmp = np.array_split(train[train.Category == i].sample(frac=1, random_state=420), n_folds)\n",
    "    for n in range(n_folds):\n",
    "        splits[n].append(split_tmp[n])\n",
    "        \n",
    "splits = [pd.concat(s).sample(frac=1, random_state=69) for s in splits]\n",
    "\n",
    "folds = [[] for _ in range(n_folds)]\n",
    "valids = []\n",
    "test = list(range(n_folds))\n",
    "for n in range(n_folds):\n",
    "    valids.append(splits[n])\n",
    "    if splits[:n]:\n",
    "        folds[n].append(pd.concat(splits[:n]))\n",
    "    if splits[n+1:]:\n",
    "        folds[n].append(pd.concat(splits[n+1:]))\n",
    "\n",
    "folds = [pd.concat(f).sample(frac=1, random_state=1337) for f in folds]\n",
    "['train %d valid %d total %d match %r' % (folds[n].shape[0], valids[n].shape[0], folds[n].shape[0] + valids[n].shape[0], \n",
    "                                          folds[n].shape[0] + valids[n].shape[0] == train.shape[0]) for n in range(n_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bb06115-7c8a-4e9f-b537-d2a5b8a7d088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1370, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pm.drop(train.index)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03c39f0-89b5-4fbb-8332-352b64b2b571",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a97fea6-f215-4997-a754-baaf61cbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(train_all_fn):\n",
    "    os.remove(train_all_fn)\n",
    "    \n",
    "train.to_pickle(train_all_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5929be0c-30cc-4506-a24e-c88db1e27ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_folds):\n",
    "    if os.path.isfile(train_fn % n):\n",
    "        os.remove(train_fn % n)\n",
    "    if os.path.isfile(valid_fn % n):\n",
    "        os.remove(valid_fn % n)\n",
    "\n",
    "    folds[n].to_pickle(train_fn % n)\n",
    "    valids[n].to_pickle(valid_fn % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a20d00d-f44c-4166-98ec-954eed54adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(test_fn):\n",
    "    os.remove(test_fn)\n",
    "\n",
    "test.to_pickle(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc192a-315d-4761-a2b5-5bb6b323bf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
