model_storage_directory: ./checkpoints/multi-9f-k0
batch_size: 10
epochs: 200
evaluation_interval: 5
checkpoint_interval: 10
;use_tensorboard

bert_model_path: ./pretrained_bert_tf/biobert_pretrain_output_all_notes_150000
#Find it here: https://github.com/EmilyAlsentzer/clinicalBERT
#bert_model_path: /export/b18/elliot/pretrained_bert_tf/biobert_pretrain_output_all_notes_150000

labels: ONE, THREE, FOUR, FIVE, SIX, SEVEN, EIGHT, NINE, TEN
architecture: DocumentBertLSTM
#freeze_bert
bert_batch_size: 7

cuda
learning_rate: 5e-5
weight_decay: 0
